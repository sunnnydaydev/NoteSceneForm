# 增强人脸

# 工作原理

使用Ar技术自动检测到人脸的不同区域，然后在这些区域叠加一些3d模型或纹理以达到增强人脸的效果~

为了在检测到的人脸上正确叠加纹理与3d模型，ArCore会根据检测到的人脸生成"增强的人脸网格"。"增强的人脸网格"是人脸的虚拟表
现形式，由人脸网格，面部区域，和用户头部中心组成。

当用户的脸部被摄像机捕捉时Arcore会：

先定义中心姿势 (Center Pose) ，是指人头的物理中心（头部中心在鼻子的后面，是整个头部的中心。）。所以说，这个点不在表面
而在里面。 然后是脸部网格 (Face Mesh) ， 包含数百个顶点。每个点的位置，都是参照物理中心点来定义的。

这个API把人脸分为三个区域来识别姿势：左前额(Left Forehead) ，右前额(Right Forehead) ，以及鼻尖(Nose Tip) 。

把中心姿势、脸部网格以及三个区域结合到一起，ARCore就这样支持精细的三维AR效果了。

SceneForm的脸部网格方向

![](https://developers.google.cn/static/sceneform/images/axis-diagrams-java2.jpg)

# 如何增强面部呢？

需要我们拿到由艺术家在 3D 建模和动画软件中提前创建的fbx模型文件，以及自定义的纹理文件（通常为png）

# code eg

```kotlin
/**
 * Create by SunnyDay /11/17 15:13:08
 */
class FaceArFragment:ArFragment() {
    override fun getSessionConfiguration(session: Session?): Config {
        val config = Config(session)
        //支持面部网格
        config.augmentedFaceMode = AugmentedFaceMode.MESH3D
        return config
    }

    override fun getSessionFeatures(): Set<Session.Feature?>? {
        //设置前摄像头
        return EnumSet.of(Session.Feature.FRONT_CAMERA)
    }


    override fun onCreateView(
        inflater: LayoutInflater,
        container: ViewGroup?,
        savedInstanceState: Bundle?
    ): View? {
        val frameLayout =
            super.onCreateView(inflater, container, savedInstanceState) as FrameLayout?
        //隐藏指示默认的view
        planeDiscoveryController.hide()
        planeDiscoveryController.setInstructionView(null)
        return frameLayout
    }

}
```

```kotlin
class FoxActivity : AppCompatActivity() {
    companion object {
        private const val MIN_OPENGL_VERSION = 3.0
    }

    private var foxFragment: FaceArFragment? = null
    private var faceRegionRenderable: Renderable? = null
    private var faceMeshTexture: Texture? = null
    private val faceNodeMap = mutableMapOf<AugmentedFace, AugmentedFaceNode>()

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        if (!checkIsSupportedDeviceOrFinish(this)) {
            finish()
            return
        }
        setContentView(R.layout.activity_fox)
        foxFragment = supportFragmentManager.findFragmentById(R.id.foxFragment) as FaceArFragment?

        // 1、构建可渲染对象
        ModelRenderable
            .builder()
            .setSource(this, R.raw.fox_face)
            .build()
            .thenAccept {
                faceRegionRenderable = it
                it.isShadowCaster = false
                it.isShadowReceiver = false
            }
        //2、构建纹理对象
        Texture
            .builder()
            .setSource(this, R.drawable.fox_face_mesh_texture)
            .build()
            .thenAccept {
                faceMeshTexture = it
            }.exceptionally {
                Timber.d("Unable to load andy renderable")
                null
            }

        // 3、获取arSceneView、Scene对象
        val arSceneView = foxFragment?.arSceneView
        val scene = arSceneView?.scene

        arSceneView?.cameraStreamRenderPriority = Renderable.RENDER_PRIORITY_FIRST
        // 4、场景实时帧更新监听
        scene?.addOnUpdateListener {
            if (faceRegionRenderable == null || faceMeshTexture == null) return@addOnUpdateListener
            //拿面部信息（主要拿未增强时的脸部信息）
            val faceList = arSceneView.session?.getAllTrackables(AugmentedFace::class.java)
            faceList?.forEach {

                if (!faceNodeMap.containsKey(it)) {
                    // 创建一个面部增强的节点（把面部信息传递过来）
                    val faceNode = AugmentedFaceNode(it)
                    // 进行面部增强渲染
                    faceNode.setParent(scene)
                    faceNode.renderable = faceRegionRenderable
                    faceNode.faceMeshTexture = faceMeshTexture
                    faceNodeMap[it] = faceNode
                }
            }

            // 回收操作
            val iterator:MutableIterator<Map.Entry<AugmentedFace, AugmentedFaceNode>> = faceNodeMap.entries.iterator()
            while (iterator.hasNext()){
                val entry: Map.Entry<AugmentedFace, AugmentedFaceNode> = iterator.next()
                val face = entry.key
                if (face.trackingState==TrackingState.STOPPED){
                    val faceNode = entry.value
                    faceNode.setParent(null)
                    iterator.remove()
                }
            }
        }

    }

    /**
     * 安卓7.0 opengl3.0 检测
     * */
    @SuppressLint("ObsoleteSdkInt")
    private fun checkIsSupportedDeviceOrFinish(activity: Activity): Boolean {
        if (Build.VERSION.SDK_INT < Build.VERSION_CODES.N) {
            Timber.d("SceneForm requires Android N or later")
            Toast.makeText(activity, "SceneForm requires Android N or later", Toast.LENGTH_LONG)
                .show()
            activity.finish()
            return false
        }
        val openGlVersionString =
            (activity.getSystemService(Context.ACTIVITY_SERVICE) as ActivityManager)
                .deviceConfigurationInfo
                .glEsVersion
        if (openGlVersionString.toDouble() < MIN_OPENGL_VERSION) {
            Timber.d("SceneForm requires OpenGL ES 3.0 later")
            Toast.makeText(activity, "SceneForm requires OpenGL ES 3.0 or later", Toast.LENGTH_LONG)
                .show()
            activity.finish()
            return false
        }
        return true
    }
}
```

核心思想 监听场景变化事件，不断地为场景中的人脸渲染模型与纹理。




